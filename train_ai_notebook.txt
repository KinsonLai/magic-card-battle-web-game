
================================================================================
CELL 1 [MARKDOWN]
================================================================================
# 1. 安裝與引入必要套件
請先執行此區塊以安裝 PyTorch 與數據處理工具。

================================================================================
CELL 2 [CODE]
================================================================================
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import numpy as np
import pandas as pd
import json
import matplotlib.pyplot as plt
import io
import os

# 檢測環境 (Colab 或 本地)
try:
    from google.colab import files
    IS_COLAB = True
except ImportError:
    IS_COLAB = False

# 設定裝置 (優先使用 GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"使用裝置: {device}")


================================================================================
CELL 3 [MARKDOWN]
================================================================================
# 2. 上傳訓練數據 (.json)
執行此區塊，並點擊下方「選擇檔案」上傳您從遊戲中下載的 `mcts_training_data_...json` 檔案。

================================================================================
CELL 4 [CODE]
================================================================================
raw_data = []

if IS_COLAB:
    uploaded = files.upload()
    filename = list(uploaded.keys())[0]
    print(f"已讀取檔案: {filename}")
    with open(filename, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
else:
    # 本地模式：自動搜尋目錄下的 json 檔案
    import glob
    json_files = glob.glob('mcts_training_data_*.json')
    if json_files:
        latest_file = max(json_files, key=os.path.getctime)
        print(f"讀取最新的數據檔案: {latest_file}")
        with open(latest_file, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
    else:
        print("錯誤：找不到 mcts_training_data_*.json 檔案，請確保檔案在同一目錄下。")

print(f"數據筆數: {len(raw_data)}")
if len(raw_data) < 100:
    print("警告：數據量過少，建議模擬至少 50 場遊戲 (約 2000+ 筆數據) 以獲得良好效果。")


================================================================================
CELL 5 [MARKDOWN]
================================================================================
# 3. 數據預處理與特徵工程 (Feature Engineering)
將原始遊戲數據轉換為神經網路可讀的張量 (Tensor)，並進行標準化處理。

================================================================================
CELL 6 [CODE]
================================================================================
class BattleDataset(Dataset):
    def __init__(self, data, scaler=None, nation_encoder=None):
        self.samples = []
        
        # 1. 解析數據
        features = []
        nations = []
        value_targets = []
        
        for item in data:
            # 原始向量: [hp, mana, gold, soul]
            state = item['stateVector']
            features.append(state)
            nations.append([item['player']])
            value_targets.append(item['valueTarget'])

        # 2. 數值標準化 (Normalization)
        # 讓 HP, Gold 等數值縮放到 0~1 或 -1~1 之間，幫助神經網路收斂
        features = np.array(features)
        if scaler is None:
            self.scaler = StandardScaler()
            features_normalized = self.scaler.fit_transform(features)
        else:
            self.scaler = scaler
            features_normalized = self.scaler.transform(features)

        # 3. 國家 One-Hot 編碼
        # 將 'FIGHTER' 轉換為 [1, 0, 0, 0] 等格式
        if nation_encoder is None:
            self.nation_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
            nations_encoded = self.nation_encoder.fit_transform(nations)
        else:
            self.nation_encoder = nation_encoder
            nations_encoded = self.nation_encoder.transform(nations)

        # 4. 組合特徵
        self.X = np.hstack((features_normalized, nations_encoded))
        self.y_value = np.array(value_targets)
        
        # 轉換為 Tensor
        self.X = torch.FloatTensor(self.X)
        self.y_value = torch.FloatTensor(self.y_value).view(-1, 1)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y_value[idx]

if len(raw_data) > 0:
    # 建立數據集
    full_dataset = BattleDataset(raw_data)
    input_dim = full_dataset.X.shape[1]

    # 切分訓練集與驗證集 (80% 訓練, 20% 驗證)
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

    print(f"輸入特徵維度: {input_dim}")
    print(f"訓練集樣本數: {len(train_dataset)}")
    print(f"驗證集樣本數: {len(val_dataset)}")
else:
    print("無數據，跳過數據集建立。")


================================================================================
CELL 7 [MARKDOWN]
================================================================================
# 4. 建構神經網路模型 (ResNet-MLP)
使用帶有殘差連接 (Residual Connection) 的全連接層，這與 AlphaZero 的核心設計理念相似，能有效處理複雜的策略評估。

================================================================================
CELL 8 [CODE]
================================================================================
class ResidualBlock(nn.Module):
    def __init__(self, hidden_dim):
        super(ResidualBlock, self).__init__()
        self.fc = nn.Linear(hidden_dim, hidden_dim)
        self.bn = nn.BatchNorm1d(hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2) # 防止過擬合

    def forward(self, x):
        residual = x
        out = self.fc(x)
        out = self.bn(out)
        out = self.relu(out)
        out = self.dropout(out)
        out += residual # 殘差連接
        return out

class MagicZeroNet(nn.Module):
    def __init__(self, input_dim, hidden_dim=128):
        super(MagicZeroNet, self).__init__()
        
        # 特徵提取層
        self.initial_layer = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU()
        )
        
        # 殘差塔 (深層思考)
        self.res_blocks = nn.Sequential(
            ResidualBlock(hidden_dim),
            ResidualBlock(hidden_dim),
            ResidualBlock(hidden_dim)
        )
        
        # 價值頭 (Value Head): 評估當前勝率 (-1 ~ 1)
        self.value_head = nn.Sequential(
            nn.Linear(hidden_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Tanh() # 輸出範圍限制在 -1 到 1
        )

    def forward(self, x):
        x = self.initial_layer(x)
        x = self.res_blocks(x)
        value = self.value_head(x)
        return value

if 'input_dim' in locals():
    model = MagicZeroNet(input_dim=input_dim).to(device)
    print(model)


================================================================================
CELL 9 [MARKDOWN]
================================================================================
# 5. 開始訓練 (Training)
包含 Early Stopping 機制，當驗證集誤差不再下降時自動停止，防止過度擬合。

================================================================================
CELL 10 [CODE]
================================================================================
if 'train_loader' in locals():
    # 超參數設定
    LEARNING_RATE = 0.001
    EPOCHS = 50
    patience = 10 # Early Stopping 容忍度

    criterion = nn.MSELoss() # 均方誤差 (適合勝率預測)
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)

    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    patience_counter = 0

    print("--- 開始訓練 ---")

    for epoch in range(EPOCHS):
        # 訓練模式
        model.train()
        running_loss = 0.0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * inputs.size(0)
        
        epoch_train_loss = running_loss / len(train_dataset)
        train_losses.append(epoch_train_loss)

        # 驗證模式
        model.eval()
        running_val_loss = 0.0
        with torch.no_grad():
            for inputs, targets in val_loader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                running_val_loss += loss.item() * inputs.size(0)
                
        epoch_val_loss = running_val_loss / len(val_dataset)
        val_losses.append(epoch_val_loss)
        
        # 學習率調整
        scheduler.step(epoch_val_loss)

        print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f}")

        # Check Early Stopping
        if epoch_val_loss < best_val_loss:
            best_val_loss = epoch_val_loss
            torch.save(model.state_dict(), 'best_model.pth')
            patience_counter = 0
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"Early stopping at epoch {epoch+1}")
                break

    print("訓練完成！")

    # 繪製損失曲線
    try:
        plt.figure(figsize=(10, 5))
        plt.plot(train_losses, label='Train Loss')
        plt.plot(val_losses, label='Validation Loss')
        plt.title('Training Process')
        plt.xlabel('Epochs')
        plt.ylabel('MSE Loss')
        plt.legend()
        plt.grid(True)
        plt.savefig('training_loss.png')
        if IS_COLAB:
            plt.show()
        else:
            print("Loss plot saved as training_loss.png")
    except Exception as e:
        print(f"Plotting failed: {e}")


================================================================================
CELL 11 [MARKDOWN]
================================================================================
# 6. 測試模型預測能力
我們手動輸入一些極端情況，看看 AI 是否學會了判斷局勢。

================================================================================
CELL 12 [CODE]
================================================================================
if 'full_dataset' in locals() and os.path.exists('best_model.pth'):
    model.load_state_dict(torch.load('best_model.pth'))
    model.eval()

    # 定義測試函數
    def predict_win_rate(hp, mana, gold, soul, nation):
        # 1. 建構原始數據
        raw_input = np.array([[hp, mana, gold, soul]])
        
        # 2. 數值標準化
        norm_input = full_dataset.scaler.transform(raw_input)
        
        # 3. 國家編碼
        nation_input = full_dataset.nation_encoder.transform([[nation]])
        
        # 4. 組合
        final_input = np.hstack((norm_input, nation_input))
        tensor_input = torch.FloatTensor(final_input).to(device)
        
        # 5. 預測
        with torch.no_grad():
            score = model(tensor_input).item()
        
        return score

    print("--- AI 局勢判斷測試 ---")

    # 測試情境 1: 完美狀態
    score1 = predict_win_rate(hp=200, mana=100, gold=500, soul=3, nation='MAGIC')
    print(f"情境 1 [滿血/滿魔/富裕/光之姿態 - 法師]: 勝率預測 {score1:.2f} (應接近 1.0)")

    # 測試情境 2: 瀕死狀態
    score2 = predict_win_rate(hp=10, mana=0, gold=0, soul=0, nation='FIGHTER')
    print(f"情境 2 [殘血/空魔/破產 - 鬥士]: 勝率預測 {score2:.2f} (應接近 -1.0)")

    # 測試情境 3: 普通開局
    score3 = predict_win_rate(hp=100, mana=50, gold=100, soul=0, nation='COMMERCIAL')
    print(f"情境 3 [初始狀態 - 商人]: 勝率預測 {score3:.2f} (應接近 0.0)")


================================================================================
CELL 13 [MARKDOWN]
================================================================================
# 7. 匯出模型與標準化參數
執行此區塊以將訓練好的模型 (`brain.pth`) 以及標準化參數打包下載。之後您可以在網頁前端使用 TensorFlow.js 或 ONNX Runtime 載入此模型。

================================================================================
CELL 14 [CODE]
================================================================================
if 'full_dataset' in locals():
    import pickle

    # 儲存標準化器以便前端使用 (需要知道 mean 和 scale)
    scaler_params = {
        'mean': full_dataset.scaler.mean_.tolist(),
        'scale': full_dataset.scaler.scale_.tolist(),
        'nations': full_dataset.nation_encoder.categories_[0].tolist()
    }

    with open('model_params.json', 'w') as f:
        json.dump(scaler_params, f)

    if IS_COLAB:
        files.download('best_model.pth')
        files.download('model_params.json')
    else:
        print("檔案已儲存：best_model.pth, model_params.json")

    print("檔案已準備。")
    print("在網頁端，您需要使用與此處相同的邏輯來預處理輸入數據：")
    print(f"Normalization Formula: (Input - Mean) / Scale")
